%
% Abstract (does not appear in the Table of Contents)
\chapter*{Abstract}%

Reference or trajectory tracking is one of the requirements in order to carry out a complex robotic task. Capability to perform a precise tracking with minimum possible error is crucial for the robots that are to be deployed at manufacturing industries such as semiconductor, automotive and recently, an emerging application of 3D printing.

The approach used in the past has been to design model based controllers which involve feedback and feedforward control or more recently, a predictive control. The drawback of such scheme, however, lies on the requirements of system model as a slight model mismatch could lead to poor tracking performance. For a repetitive control error, researchers have designed the so called Iterative Learning Control (ILC). In this literature study, a new method to optimize the tracking performance of nominal controller using reinforcement learning (RL) is proposed. 

Throughout the literature study, the existing work for RL-based tracking control clusters into 3 approaches: RL for optimal tracking (Lewis et al.), RL-based dynamic tuning (Brujeni et al.), and nonlinear compensator via RL (Bayiz et al.). The advantages, limitations and practical challenges of the 3 approaches are discussed. These criterion serves as a basis to select one method which will be developed and implemented during the thesis. Furthermore, the testbed for the thesis which is a UR5 3D printing robot are also presented. Finally, the literature study concludes with the research plan and discussion.