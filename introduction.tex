%
% Introduction
\chapter{Introduction} \label{chap::intro}
Reference or trajectory tracking is one of the building blocks to perform a complex task in robotics. Given a desired path/trajectory, the robot must be able to follow it as quickly as possible with minimum error. Capability to perform this precise tracking is crucial for robots that are to be deployed at manufacturing industries such as semiconductor, automotive, and recently, the emerging application of 3D printing. 

Statistics by International Federation of Robotics (IFR) \cite{IFR2014} shows that the global sales of industrial robots continues to increase steadily. In 2014, it is expected that the total number of industrial robots installed would reach 205,000 units, a rise of approximately 15 \% from the previous year. The survey points out that the mature markets such as automotive, electronics, and metal are responsible for such growth. 

Meanwhile, there is also a growing interests in applying robots to relatively new applications such as 3D printing, architecture, and art. For instance, research done by Gramazio et. al \cite{Helm2014} \cite{Lloret2014} aims to push the capability of industrial robots to make direct fabrication based on CAD model a reality. The advantage of using robots over conventional CNC machines lies on their flexibility, easy-to-adapt feature, and high \ac{DoF} -- enabling execution of difficult configuration in \ac{3D} space. These aforementioned applications demand high precision since a minuscule error could lead to a defect in product or even worse, a disaster. Therefore a precise, accurate reference tracking capability is inevitable.

In order to achieve this, a reference tracking control is needed. However, a robot being a physical system is stymied by non-linearities, noises, and external disturbances that are difficult to model, let alone compensate. This unknown properties often hinders the controller to perform optimally. A class of controllers which solely depends on the system's model will surely suffer a poor tracking accuracy. The natural answer to this problem is to introduce a controller capable of adjusting its parameter overtime by comparing the reference to the actual trajectory. By doing so, the controller will have an extra degree of freedom to compensate for the unknown properties hence improving the tracking quality. The controller with self-adjusting characteristic are called adaptive controller.

In this thesis, a method to improve the performance of nominal controller by using \ac{RL} is proposed. Despite decades of extensive research on \ac{RL}, its application to optimize tracking problem in robotics is still relatively unexplored. Based on the literature, there are three potential approaches to address this problem. The first one comes from the work of Lewis et. al. on \ac{RL} for optimal control. Lewis and his group have been developing a comprehensive research on \ac{RL} for solving the solution to adaptive optimal control. Their research has been extended for discrete \cite{Kiumarsi20141167} and continuous time \cite{Modares6760477}, for linear \cite{Kiumarsi6760476} and non-linear system \cite{Kiumarsi6918527}. Furthermore, their technique could also be applied to Q-learning \cite{Kiumarsi20141167} and actor-critic structure \cite{Kiumarsi6918527}. The second approach uses the notion of adaptive gain scheduling which further bifurcates into two methods: directly learning the controller's gains with \ac {RL} \cite{Brujeni5669655} and applying \ac{PI$^2$} algorithm to \ac {DMP} for optimizing the robot's trajectory \cite{Buchli2010} \cite{Buchli6037312} . The latter was not designed for tracking in the first place, but rather to optimize gain scheduling for variable impedance control task. Nevertheless, it has some properties which makes it interesting for tracking application. Finally, the third approach is a relatively new method by using \ac{RL} to learn a disturbance compensation signal for nonlinear system. This method, first proposed by Bayiz et. al. \cite{Efe2014}, would provide an additive signal to the control input. Having explained the motivation of this thesis, now we are ready to define the research problem.



\section{Problem Definition}
The fundamental problem in this literature study concerns the non-optimal performance of nominal controller with respect to reference tracking task. Hence the research question can be raised as follows.

\textit{"Is it possible to integrate Reinforcement Learning technique to a nominal controller in a certain structure such that reference tracking performance of the controlled system significantly improves?"}

While conducting a research, it is often wise to restrict oneself to a simple context, but still captures the essential elements of the original problem \cite{einstein}. Therefore, in answering this question, some simplifying assumptions are made.

\begin{enumerate}
	\item The system to be controlled is fully actuated
	\item The system to be controlled is observable. This assumption is necessary in order to satisfy Markov property \cite{sutton1998reinforcement}.
	\item Nominal, stabilizing controller is available	
	\item Identification reveals some information about the system, but alone is not adequate to design an accurate reference tracking controller.
\end{enumerate}

\section{Goal of the Thesis}

The goal of this thesis are as follows:
\begin{enumerate}
\item To provide a general framework to improving the tracking control using \ac{RL}
\item To apply and compare existing method of \ac{RL} for tracking application to the 3D printing robot setup
\item To come up with modification and improvement of the previous methods
\end{enumerate}

\section{Literature Study Approach}
In order to build a strong theoretical foundation for later implementation, the following literature approach is used. The order does not necessarily represent a sequential process.
\begin{enumerate}
	\item To gather as many relevant papers as possible from reputable academic search engines. Relevant means papers which deal with \ac{RL} and control system. Additional pointer to tracking problem is heavily considered. Examples of sources being used are Web of Science, IEEE Xplore and Google Scholar.
	\item To discuss the detail of future experimental setup (UR5 \ac{3D} printing robot) with Marco de Gier, who was working on the setup at the time this literature is written.
	\item From the papers, extract existing methods which have the potential for application to the future experiments. So far, there are 3 different methods that are considered. These methods will be explained in detail in Chapter \ref{chap::survey}.
	\item Create simple simulation programs showing how each method works
	
\end{enumerate}


\section{Outline}

The structure of this literature review is arranged as follows. In the next chapter, an introductory materials of \ac{RL} is presented. This covers the framework widely used in \ac{RL}: (Markov Decision Process), the principle of value and policy iteration, the formulation of \ac{RL} for continuous space, and the actor-critic structure which suits the framework of control system. Chapter \ref{chap::survey} provides the result of literature study being conducted. This includes the detailed explanation of methods found and their comparison. The last chapter will provide explanation about the research plan.  

%\section{Nomenclature}


