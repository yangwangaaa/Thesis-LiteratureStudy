%
% Introduction
\chapter{Introduction} \label{chap::intro}
Reference or trajectory tracking is one of the building blocks to perform a complex task in robotics. Given a desired path/trajectory, the robot must be able to follow it as quickly as possible with minimum error. Capability to perform this precise tracking is crucial for robots that are to be deployed at manufacturing industries such as semiconductor, automotive, and recently, the emerging application of 3D printing. 

Statistics by International Federation of Robotics (IFR) \cite{IFR2014} shows that the global sales of industrial robots continues to increase steadily. In 2014, it is expected that the total number of industrial robots installed reaches 205,000 units, a rise of approximately 15 \% from previous year. The survey points out that the mature markets such as automotive, electronics, and metal are responsible for such growth. 

Meanwhile, there is also a growing interests in applying robots to relatively new applications such as 3D printing, architecture, and art. For instance, research done by Gramazio et. al \cite{Helm2014} \cite{Lloret2014} aims to push the capability of industrial robots to make direct fabrication based on CAD model a reality. The advantage of using robots over conventional CNC machines lies on their flexibility, easy-to-adapt feature, and high \ac{DoF} -- enabling execution of difficult configuration in \ac{3D} space. These aforementioned applications demand high precision since a minuscule of error could lead to a defect product or even worse, a disaster. Therefore a precise, accurate reference tracking capability is inevitable.

In order to achieve this, a reference tracking control is needed. However, a robot brings along non-linearities, noises, and external disturbances that are difficult to model, let alone compensate. This unknown properties often hinders the controller to perform optimally. A class of controllers which solely depends on the system's model will surely suffer a poor tracking accuracy. The natural answer to this problem is to introduce a controller capable of adjusting its parameter overtime by comparing the reference to the actual trajectory. By doing so, the controller will have an extra degree of freedom to compensate for the unknown properties hence improving the tracking quality. The controller of such characteristic belongs to the class of adaptive controller.

In this thesis, a method to improve the performance of nominal controller by using \ac{RL} is proposed. Despite decades of extensive research on \ac{RL}, its application to optimize tracking problem in robotics is still a relatively unexplored topic. Based on the literature, there are three potential approaches to address the tracking problem. The first one comes from the work of Lewis et. al. on \ac{RL} for optimal control. Lewis and his group have been developing a comprehensive research on \ac{RL} for solving the solution to adaptive optimal control. Their research has been extended for discrete \cite{Kiumarsi20141167} and continuous time \cite{Modares6760477}, for linear \cite{Kiumarsi6760476} and non-linear system \cite{Kiumarsi6918527}. Furthermore, their technique could also be applied in Q-learning \cite{Kiumarsi20141167} and actor-critic structure \cite{Kiumarsi6918527}. The second approach is proposed by Bayiz et. al. in \cite{Efe2014}. The paper discusses a slightly different approach by using \ac{RL} to learn disturbance compensation for nonlinear system. This disturbance compensation acts as an additive input signal to the control signal. Finally, the third approach uses the notion of adaptive gain scheduling. Buchli et.al present an algorithm called \ac{PI$^2$} to vary the gain of a \ac{PD} controller in order to achieve a desired terminal state \cite{Buchli2010} \cite{Buchli6037312}. Having explained the motivation of this thesis, now we are ready to define the research problem.



\section{Problem Definition}
The fundamental problem in this literature study concerns the non-optimal performance of nominal controller with respect to reference tracking task. Hence the research question can be raised as follows.

\textit{"Is it possible to integrate Reinforcement Learning technique to a nominal controller in a certain structure such that reference tracking performance of the controlled system significantly improves?"}

While conducting a research, it is often wise to restrict oneself to a simple context, but still captures the essential elements of the original problem \cite{einstein}. Therefore, in answering this question, some simplifying assumptions are made.

\begin{enumerate}
	\item The system to be controlled is fully actuated
	\item The system to be controlled is observable. This assumption is necessary in order to satisfy Markov property \cite{sutton1998reinforcement}.
	\item Nominal, stabilizing controller is available	
	\item Identification reveals some information about the system, but alone is not adequate to design an accurate reference tracking controller.
\end{enumerate}

\section{Goal of the Thesis}

The goal of this thesis are as follows:
\begin{enumerate}
\item To provide a general framework of improving tracking control using \ac{RL}
\item To apply and compare existing method of \ac{RL} for tracking application to the 3D printing robot setup
\item To come up with modification or improvement of previous methods
\end{enumerate}

\section{Literature Study Approach}
In order to build a strong theoretical foundation for later implementation, the following literature approach is used. The order does not necessarily represent a sequential process.
\begin{enumerate}
	\item To gather as many relevant papers as possible from reputable academic search engines. Relevant means papers which deal with \ac{RL} and control system. Additional pointer to tracking problem is heavily considered. Examples of sources being used are Web of Science, IEEE Xplore and Google Scholar.
	\item To discuss the detail of future experimental setup (UR5 \ac{3D} printing robot) with Marco de Gier, who was working on the setup at the time this literature is written.
	\item From the papers, extract existing methods which have the potential for application to the future experiments. So far, there are 3 different methods that are considered. These methods will be explained in detail in Chapter \ref{chap::survey}.
	\item Create simple simulation programs showing how each method works
	
\end{enumerate}


\section{Outline}

The structure of this literature review is arranged as follows. In the next chapter, an introductory materials of \ac{RL} is presented. This covers the framework widely used in \ac{RL} (Markov Decision Process), the principle of value and policy iteration, the formulation of \ac{RL} for continuous space, and the actor-critic structure which suits the framework of control system. Chapter \ref{chap::survey} provides the result of literature study being conducted. This includes the detailed explanation of methods found and their comparison. Furthermore, a new controller is proposed. 

%\section{Nomenclature}


