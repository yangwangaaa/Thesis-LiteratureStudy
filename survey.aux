\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{Abbeel}
\citation{NIPS2007_3253}
\citation{4543641}
\citation{4048052}
\citation{299157}
\citation{1044377}
\citation{126844}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Reinforcement Learning for Tracking Problem: A Survey}{9}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap::survey}{{3}{9}{Reinforcement Learning for Tracking Problem: A Survey}{chapter.3}{}}
\undonewlabel{acro:RL}
\newlabel{acro:RL}{{3}{9}{Reinforcement Learning for Tracking Problem: A Survey}{section*.20}{}}
\acronymused{RL}
\acronymused{RL}
\acronymused{RL}
\acronymused{RL}
\acronymused{RL}
\acronymused{RL}
\acronymused{RL}
\acronymused{RL}
\acronymused{RL}
\undonewlabel{acro:ILC}
\newlabel{acro:ILC}{{3}{9}{Reinforcement Learning for Tracking Problem: A Survey}{section*.21}{}}
\acronymused{ILC}
\acronymused{ILC}
\acronymused{ILC}
\@writefile{toc}{\contentsline {section}{\numberline {3-1}Reinforcement Learning for Optimal Tracking Control}{9}{section.3.1}}
\newlabel{sec:rl_lqt}{{3-1}{9}{Reinforcement Learning for Optimal Tracking Control}{section.3.1}{}}
\acronymused{RL}
\citation{Kiumarsi6760476}
\citation{Kiumarsi6760476}
\citation{lewis1995optimal}
\acronymused{RL}
\acronymused{RL}
\undonewlabel{acro:PI}
\newlabel{acro:PI}{{3-1}{10}{Reinforcement Learning for Optimal Tracking Control}{section*.22}{}}
\acronymused{PI}
\undonewlabel{acro:LQT}
\newlabel{acro:LQT}{{3-1}{10}{Reinforcement Learning for Optimal Tracking Control}{section*.23}{}}
\acronymused{LQT}
\@writefile{toc}{\contentsline {subsection}{\numberline {3-1-1}Standard LQT problem}{10}{subsection.3.1.1}}
\acronymused{LQT}
\undonewlabel{acro:LTI}
\newlabel{acro:LTI}{{3-1-1}{10}{Standard LQT problem}{section*.24}{}}
\acronymused{LTI}
\newlabel{eq:ss}{{3-1}{10}{Standard LQT problem}{equation.3.1.1}{}}
\undonewlabel{acro:SISO}
\newlabel{acro:SISO}{{3-1-1}{10}{Standard LQT problem}{section*.25}{}}
\acronymused{SISO}
\newlabel{eq:infcost}{{3-2}{10}{Standard LQT problem}{equation.3.1.2}{}}
\newlabel{eq:noncausal}{{3-4}{10}{Standard LQT problem}{equation.3.1.4}{}}
\undonewlabel{acro:ARE}
\newlabel{acro:ARE}{{3-1-1}{11}{Standard LQT problem}{section*.26}{}}
\acronymused{ARE}
\@writefile{toc}{\contentsline {subsection}{\numberline {3-1-2}Causal Representation of the LQT}{11}{subsection.3.1.2}}
\newlabel{eq:lqtlyap}{{3-12}{11}{Causal Representation of the LQT}{equation.3.1.12}{}}
\citation{1099755}
\citation{Kiumarsi20141167}
\citation{Modares20141780}
\newlabel{eq:lqtbellman}{{3-15}{12}{Causal Representation of the LQT}{equation.3.1.15}{}}
\newlabel{eq:lqtare}{{3-17}{12}{Causal Representation of the LQT}{equation.3.1.17}{}}
\newlabel{eq:opt_u}{{3-18}{12}{Causal Representation of the LQT}{equation.3.1.18}{}}
\acronymused{RL}
\acronymused{RL}
\@writefile{toc}{\contentsline {subsection}{\numberline {3-1-3}\ac {RL} for Solving the LQT ARE}{12}{subsection.3.1.3}}
\newlabel{eq:lyap_lqt}{{3-20}{12}{\ac {RL} for Solving the LQT ARE}{equation.3.1.20}{}}
\acronymused{PI}
\acronymused{PI}
\acronymused{PI}
\citation{Buchli2010}
\citation{Buchli6037312}
\citation{buchli2011learning}
\citation{theodorou2010generalized}
\citation{buchli2011learning}
\citation{375142}
\citation{5229855}
\citation{1684589}
\citation{6606304}
\citation{572744}
\citation{556252}
\citation{882916}
\citation{Brujeni5669655}
\acronymused{RL}
\newlabel{alg:off_pi}{{4}{13}{\ac {RL} for Solving the LQT ARE}{algocfline.4}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Offline Policy Iteration\relax }}{13}{algocf.4}}
\newlabel{alg:on_pi}{{5}{13}{\ac {RL} for Solving the LQT ARE}{algocfline.5}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces Online Policy Iteration\relax }}{13}{algocf.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3-1-4}Conclusion}{13}{subsection.3.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3-2}Dynamic Tuning via Reinforcement Learning}{13}{section.3.2}}
\newlabel{sec:dytun}{{3-2}{13}{Dynamic Tuning via Reinforcement Learning}{section.3.2}{}}
\acronymused{RL}
\undonewlabel{acro:PI$^2$}
\newlabel{acro:PI$^2$}{{3-2}{13}{Dynamic Tuning via Reinforcement Learning}{section*.27}{}}
\acronymused{PI$^2$}
\@writefile{toc}{\contentsline {subsection}{\numberline {3-2-1}Direct Tuning of Nominal Controller}{13}{subsection.3.2.1}}
\citation{Brujeni5669655}
\citation{sutton1998reinforcement}
\undonewlabel{acro:MIMO}
\newlabel{acro:MIMO}{{3-2-1}{14}{Direct Tuning of Nominal Controller}{section*.28}{}}
\acronymused{MIMO}
\acronymused{RL}
\acronymused{RL}
\acronymused{RL}
\undonewlabel{acro:TD}
\newlabel{acro:TD}{{3-2-1}{14}{Direct Tuning of Nominal Controller}{section*.29}{}}
\acronymused{TD}
\undonewlabel{acro:SARSA}
\newlabel{acro:SARSA}{{3-2-1}{14}{Direct Tuning of Nominal Controller}{section*.30}{}}
\acronymused{SARSA}
\@writefile{lof}{\contentsline {figure}{\numberline {3-1}{\ignorespaces Gain scheduling of Nominal controller using \ac {RL}. In this case, a PID controller is used\relax }}{14}{figure.caption.31}}
\acronymused{RL}
\newlabel{fig:dynamictuning}{{3-1}{14}{Gain scheduling of Nominal controller using \ac {RL}. In this case, a PID controller is used\relax }{figure.caption.31}{}}
\acronymused{SARSA}
\acronymused{SARSA}
\acronymused{SARSA}
\acronymused{SARSA}
\acronymused{SARSA}
\acronymused{RL}
\citation{Buchli2010}
\citation{Buchli6037312}
\citation{buchli2011learning}
\@writefile{lof}{\contentsline {figure}{\numberline {3-2}{\ignorespaces A sequence of state and action\relax }}{15}{figure.caption.32}}
\newlabel{fig:sarsa}{{3-2}{15}{A sequence of state and action\relax }{figure.caption.32}{}}
\newlabel{alg:sarsa}{{6}{15}{Direct Tuning of Nominal Controller}{algocfline.6}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces SARSA algorithm\relax }}{15}{algocf.6}}
\acronymused{SARSA}
\acronymused{SARSA}
\acronymused{RL}
\undonewlabel{acro:ISE}
\newlabel{acro:ISE}{{2}{15}{Direct Tuning of Nominal Controller}{section*.33}{}}
\acronymused{ISE}
\acronymused{SARSA}
\acronymused{PI$^2$}
\@writefile{toc}{\contentsline {subsection}{\numberline {3-2-2}Gain scheduling with \ac {PI$^2$}}{15}{subsection.3.2.2}}
\acronymused{PI$^2$}
\acronymused{PI$^2$}
\undonewlabel{acro:DoF}
\newlabel{acro:DoF}{{3-2-2}{15}{Gain scheduling with \ac {PI$^2$}}{section*.35}{}}
\acronymused{DoF}
\@writefile{loa}{\contentsline {algocf}{\numberline {7}{\ignorespaces PID gain scheduling with \ac {SARSA}\relax }}{16}{algocf.7}}
\newlabel{alg:pid_sarsa}{{7}{16}{Direct Tuning of Nominal Controller}{algocf.7}{}}
\acronymused{SARSA}
\acronymused{PI$^2$}
\acronymused{PI$^2$}
\acronymused{PI$^2$}
\citation{stengel1994}
\citation{oksendal2010}
\citation{5509336}
\citation{5509336}
\citation{ijspeert2002learning}
\undonewlabel{acro:HJB}
\newlabel{acro:HJB}{{3-2-2}{17}{Gain scheduling with \ac {PI$^2$}}{section*.36}{}}
\acronymused{HJB}
\newlabel{eq:kolmo_pde}{{3-27}{17}{Gain scheduling with \ac {PI$^2$}}{equation.3.2.27}{}}
\undonewlabel{acro:PDE}
\newlabel{acro:PDE}{{3-2-2}{17}{Gain scheduling with \ac {PI$^2$}}{section*.37}{}}
\acronymused{PDE}
\newlabel{eq:pathintegral}{{3-28}{17}{Gain scheduling with \ac {PI$^2$}}{equation.3.2.28}{}}
\acronymused{PI$^2$}
\undonewlabel{acro:DMP}
\newlabel{acro:DMP}{{3-2-2}{17}{Gain scheduling with \ac {PI$^2$}}{section*.38}{}}
\acronymused{DMP}
\acronymused{DMP}
\citation{Buchli2010}
\citation{Buchli6037312}
\citation{Efe2014}
\citation{Grondman6096441}
\citation{Efe2014}
\citation{Kiumarsi6918527}
\citation{Grondman6096441}
\acronymused{DMP}
\acronymused{PI$^2$}
\acronymused{PI$^2$}
\acronymused{PI$^2$}
\acronymused{RL}
\acronymused{PI$^2$}
\acronymused{DMP}
\@writefile{toc}{\contentsline {section}{\numberline {3-3}Nonlinear Input Compensation via Reinforcement Learning}{18}{section.3.3}}
\newlabel{sec:nl_comp}{{3-3}{18}{Nonlinear Input Compensation via Reinforcement Learning}{section.3.3}{}}
\undonewlabel{acro:DCSC}
\newlabel{acro:DCSC}{{3-3}{18}{Nonlinear Input Compensation via Reinforcement Learning}{section*.39}{}}
\acronymused{DCSC}
\acronymused{RL}
\acronymused{RL}
\undonewlabel{acro:MLAC}
\newlabel{acro:MLAC}{{3-3}{18}{Nonlinear Input Compensation via Reinforcement Learning}{section*.40}{}}
\acronymused{MLAC}
\@writefile{toc}{\contentsline {subsection}{\numberline {3-3-1}Actor-critic formulation}{18}{subsection.3.3.1}}
\undonewlabel{acro:LLR}
\newlabel{acro:LLR}{{3-3-1}{18}{Actor-critic formulation}{section*.41}{}}
\acronymused{LLR}
\acronymused{LQT}
\@writefile{lof}{\contentsline {figure}{\numberline {3-3}{\ignorespaces Block diagram of robot with \ac {RL} block acting as an additive compensator\relax }}{19}{figure.caption.42}}
\acronymused{RL}
\newlabel{fig:blockdiagram}{{3-3}{19}{Block diagram of robot with \ac {RL} block acting as an additive compensator\relax }{figure.caption.42}{}}
\acronymused{LLR}
\@writefile{toc}{\contentsline {subsection}{\numberline {3-3-2}\ac {LLR} Function Approximator}{19}{subsection.3.3.2}}
\acronymused{LLR}
\acronymused{LLR}
\@setckpt{survey}{
\setcounter{page}{21}
\setcounter{equation}{42}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{3}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{3}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{lstnumber}{1}
\setcounter{Item}{13}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{32}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{7}
\setcounter{algocfproc}{7}
\setcounter{algocf}{7}
\setcounter{lstlisting}{0}
\setcounter{section@level}{2}
}
