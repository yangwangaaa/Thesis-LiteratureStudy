@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={28},
  year={1998},
  publisher={MIT press}
}


@INPROCEEDINGS{einstein,
  title={On the Method of Theoretical Physics},
  author={Albert Einstein},
  volume={1},
  year={1934},
  pages={163-169}, 
  publisher={Philosophy of Science}
}

@INPROCEEDINGS{Brujeni5669655, 
author={Brujeni, L.A. and Jong Min Lee and Shah, S.L.}, 
booktitle={Control Automation and Systems (ICCAS), 2010 International Conference on}, 
title={Dynamic tuning of PI-controllers based on model-free Reinforcement Learning methods}, 
year={2010}, 
month={Oct}, 
pages={453-458}, 
keywords={PI control;chemical engineering;control engineering computing;delays;
learning (artificial intelligence);state feedback;CSTH;FOPTD;Pi-controllers;RL;
continuous stirred tank heater;dynamic tuning;feedback controllers;
first order plus time delay;model free reinforcement learning methods;
plant model mismatch;Adaptation model;Chemicals;Process control;Simulation;
Temperature control;Training;Tuning;Dynamic Tuning;PI-Controller;
Reinforcement Learning;SARSA;Self-Tuning},}

@ARTICLE{Grondman6096441, 
	author={Grondman, I. and Vaandrager, M. and Busoniu, L. and Babuska, R. and Schuitema, E.}, 
	journal={Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on}, 
	title={Efficient Model Learning Methods for Actor Critic Control}, 
	year={2012}, 
	month={June}, 
	volume={42}, 
	number={3}, 
	pages={591-602}, 
	keywords={control engineering computing;function approximation;learning (artificial intelligence);manipulators;pendulums;position control;regression analysis;actor-critic algorithm;actor-critic control;function approximation;learning policy update;local linear regression;model learning method;model-based update rule;pendulum swing-up problem;reference model learning;reinforcement learning;robotic arm;Approximation algorithms;Encoding;Function approximation;Process control;Actor–critic;inverse model;local linear regression (LLR);machine learning algorithms;reinforcement learning (RL);Algorithms;Artificial Intelligence;Computer Simulation;Decision Support Techniques;Models, Theoretical;Pattern Recognition, Automated}, 
	doi={10.1109/TSMCB.2011.2170565}, 
	ISSN={1083-4419},}

@INPROCEEDINGS{Modares6760477, 
	author={Modares, H. and Lewis, F.L.}, 
	booktitle={Decision and Control (CDC), 2013 IEEE 52nd Annual Conference on}, 
	title={Online solution to the linear quadratic tracking problem of continuous-time systems using reinforcement learning}, 
	year={2013}, 
	month={Dec}, 
	pages={3851-3856}, 
	keywords={Riccati equations;continuous time systems;feedforward;learning systems;linear systems;optimal control;LQ regulator;LQ tracker;LQT;RL techniques;algebraic Riccati equation;augmented system;command generator dynamics;continuous-time systems;feedforward term;linear quadratic tracking problem;noncausality problem;optimal control solution;reinforcement learning;tracker control;Gold}, 
	doi={10.1109/CDC.2013.6760477}, 
	ISSN={0743-1546},}

@ARTICLE{Lewis5227780, 
	author={Lewis, F.L. and Vrabie, D.}, 
	journal={Circuits and Systems Magazine, IEEE}, 
	title={Reinforcement learning and adaptive dynamic programming for feedback control}, 
	year={2009}, 
	month={Third}, 
	volume={9}, 
	number={3}, 
	pages={32-50}, 
	keywords={control engineering computing;control system synthesis;dynamic programming;feedback;learning (artificial intelligence);optimal control;adaptive dynamic programming;controller design;feedback control;man-made engineered system;natural system;optimal behavior;reinforcement learning;reward stimulus;Adaptive control;Control systems;Design engineering;Dynamic programming;Feedback control;Learning;Optimal control;Organisms;Programmable control;Systems engineering and theory}, 
	doi={10.1109/MCAS.2009.933854}, 
	ISSN={1531-636X},}

@INPROCEEDINGS{Buchli6037312, 
	author={Stulp, F. and Buchli, J. and Ellmer, A. and Mistry, M. and Theodorou, E. and Schaal, S.}, 
	booktitle={Development and Learning (ICDL), 2011 IEEE International Conference on}, 
	title={Reinforcement learning of impedance control in stochastic force fields}, 
	year={2011}, 
	month={Aug}, 
	volume={2}, 
	pages={1-6}, 
	keywords={end effectors;feedforward;learning systems;stochastic systems;biologically plausible approach;end-effector trajectories;external perturbations;feedforward command;impedance perturbations;model-free reinforcement learning algorithm;physical interaction;robot end-effector;simulated 7-DOF robot;stochastic force fields;two-fold strategy;variable impedance control;Computational modeling;Noise measurement}, 
	doi={10.1109/DEVLRN.2011.6037312}, 
	ISSN={2161-9476},}

@INPROCEEDINGS{Kiumarsi6760476, 
	author={Kiumarsi-Khomartash, B. and Lewis, F.L. and Naghibi-Sistani, M.-B. and Karimpour, A.}, 
	booktitle={Decision and Control (CDC), 2013 IEEE 52nd Annual Conference on}, 
	title={Optimal tracking control for linear discrete-time systems using reinforcement learning}, 
	year={2013}, 
	month={Dec}, 
	pages={3845-3850}, 
	keywords={Riccati equations;discrete time systems;iterative methods;learning (artificial intelligence);linear quadratic control;linear systems;neural nets;ARE;LQT;actor-critic structure;augmented algebraic Riccati equation;command generator dynamics;drift system dynamics;infinite-horizon linear quadratic tracker;linear discrete-time systems;neural networks;optimal tracking control;policy iteration;reinforcement learning;Approximation methods;Artificial neural networks;Electronic mail;Facsimile;Generators;Riccati equations;Vectors;algebraic Riccati equation;linear quadratic tracker;policy iteration;reinforcement learning}, 
	doi={10.1109/CDC.2013.6760476}, 
	ISSN={0743-1546},}

@article{Modares20141780,
	title = "Optimal tracking control of nonlinear partially-unknown constrained-input systems using integral reinforcement learning ",
	journal = "Automatica ",
	volume = "50",
	number = "7",
	pages = "1780 - 1792",
	year = "2014",
	note = "",
	issn = "0005-1098",
	doi = "http://dx.doi.org/10.1016/j.automatica.2014.05.011",
	url = "http://www.sciencedirect.com/science/article/pii/S0005109814001861",
	author = "Hamidreza Modares and Frank L. Lewis",
	keywords = "Optimal tracking control",
	keywords = "Integral reinforcement learning",
	keywords = "Input constrainers",
	keywords = "Neural networks "
}

@ARTICLE{Kiumarsi6918527, 
	author={Kiumarsi, B. and Lewis, F.L.}, 
	journal={Neural Networks and Learning Systems, IEEE Transactions on}, 
	title={Actor-Critic-Based Optimal Tracking for Partially Unknown Nonlinear Discrete-Time Systems}, 
	year={2014}, 
	month={}, 
	volume={PP}, 
	number={99}, 
	pages={1-1}, 
	keywords={Equations;Feedforward neural networks;Heuristic algorithms;Mathematical model;Nonlinear dynamical systems;Standards;Trajectory;Actor–critic algorithm;discrete-time (DT) nonlinear optimal tracking;input constraints;neural network (NN);reinforcement learning (RL)}, 
	doi={10.1109/TNNLS.2014.2358227}, 
	ISSN={2162-237X},}

@article{Kiumarsi20141167,
	title = "Reinforcement Q-learning for optimal tracking control of linear discrete-time systems with unknown dynamics ",
	journal = "Automatica ",
	volume = "50",
	number = "4",
	pages = "1167 - 1175",
	year = "2014",
	note = "",
	issn = "0005-1098",
	doi = "http://dx.doi.org/10.1016/j.automatica.2014.02.015",
	url = "http://www.sciencedirect.com/science/article/pii/S0005109814000533",
	author = "Bahare Kiumarsi and Frank L. Lewis and Hamidreza Modares and Ali Karimpour and Mohammad-Bagher Naghibi-Sistani",
	keywords = "Linear quadratic tracker",
	keywords = "Reinforcement learning",
	keywords = "Policy iteration",
	keywords = "Algebraic Riccati equation "
}


@article{Buchli2010,
	title = "Variable Impedance Control-A Reinforcement Learning Approach",
	journal = "Robotics: Science and Systems",
	year = "2010",
	note = "",
	issn = "0005-1098",
	doi = "http://dx.doi.org/10.1016/j.automatica.2014.02.015",
	url = "http://www.sciencedirect.com/science/article/pii/S0005109814000533",
	author = "Jonas Buchli and Evangelos Theodorou and Freek Stulp and Stefan Schaal",
	keywords = "Linear quadratic tracker",
	keywords = "Reinforcement learning",
	keywords = "Policy iteration",
	keywords = "Algebraic Riccati equation "
}


@article{Efe2014,
	title = "Nonlinear Disturbance Compensation and. Reference Tracking via Reinforcement. Learning with Fuzzy Approximators",
	journal = "19th IFAC World Congress",
	year = "2010",
	note = "",
	issn = "0005-1098",
	doi = "http://dx.doi.org/10.1016/j.automatica.2014.02.015",
	url = "http://www.sciencedirect.com/science/article/pii/S0005109814000533",
	author = "Y. Efe Bayiz and Robert Babuska",
	keywords = "Linear quadratic tracker",
	keywords = "Reinforcement learning",
	keywords = "Policy iteration",
	keywords = "Algebraic Riccati equation "
}

@article{IFR2014,
	title = "Industrial Robot Statistics",
	journal = "World Robotics 2014 Industrial Robots",
	year = "2014",
	note = "",
	issn = "0005-1098",
	doi = "http://dx.doi.org/10.1016/j.automatica.2014.02.015",
	url = "http://www.sciencedirect.com/science/article/pii/S0005109814000533",
	author = "International Federation of Robotics (IFR)",
	keywords = "Linear quadratic tracker",
	keywords = "Reinforcement learning",
	keywords = "Policy iteration",
	keywords = "Algebraic Riccati equation "
}

@article{Lloret2014,
	title = "Complex concrete structures: Merging existing casting techniques with digital fabrication",
	journal = "Computer-Aided Design",
	year = "2014",
	note = "",
	issn = "0005-1098",
	doi = "http://dx.doi.org/10.1016/j.automatica.2014.02.015",
	url = "http://www.sciencedirect.com/science/article/pii/S0005109814000533",
	author = "Ena Lloret and Amir R. Shahabb and Mettler Linus and Robert J. Flatt and Fabio Gramazio and Matthias Kohler and Silke Langenberg",
	keywords = "Complex concrete structures"
}

@article{Helm2014,
	title = "In-Situ Robotic Fabrication: Advanced Digital Manufacturing Beyond the Laboratory",
	journal = "Springer Tracts in Advanced Robotics 2014",
	year = "2014",
	note = "",
	issn = "0005-1098",
	doi = "http://dx.doi.org/10.1016/j.automatica.2014.02.015",
	url = "http://www.sciencedirect.com/science/article/pii/S0005109814000533",
	author = "Volker Helm and Jan Willmann and Fabio Gramazio and Matthias Kohler",
	keywords = "In-situ",
	keywords = "automated construction",
	keywords = "additive fabrication"
}

@article{babuskaRL,
  title={SC4081 Knowledge-based Control Systems lecture slide},
  author={Robert Babuska},
  publisher={Delft Center for Systems & Control, TU Delft, The Netherlands}
}

@incollection{Bertsekas,
year={2007},
isbn={978-3-540-69994-1},
booktitle={Operations Research Proceedings 2006},
volume={2006},
series={Operations Research Proceedings},
editor={Waldmann, Karl-Heinz and Stocker, UlrikeM.},
doi={10.1007/978-3-540-69995-8_11},
title={Neuro-Dynamic Programming: An Overview and Recent Results},
url={http://dx.doi.org/10.1007/978-3-540-69995-8_11},
publisher={Springer Berlin Heidelberg},
author={Bertsekas, DimitriP.},
pages={71-72},
language={English}
}



