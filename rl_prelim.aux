\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Reinforcement Learning Preliminaries}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\undonewlabel{acro:RL}
\newlabel{acro:RL}{{2}{5}{Reinforcement Learning Preliminaries}{section*.19}{}}
\acronymused{RL}
\undonewlabel{acro:MDP}
\newlabel{acro:MDP}{{2}{5}{Reinforcement Learning Preliminaries}{section*.20}{}}
\acronymused{MDP}
\acronymused{RL}
\acronymused{RL}
\@writefile{toc}{\contentsline {section}{\numberline {2-1}Goal as Cost Minimization}{5}{section.2.1}}
\acronymused{RL}
\citation{babuskaRL}
\citation{sutton1998reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {2-2}Markov Decision Process}{6}{section.2.2}}
\newlabel{sec:mdp}{{2-2}{6}{Markov Decision Process}{section.2.2}{}}
\acronymused{MDP}
\newlabel{eq:markov}{{2-2}{6}{Markov Decision Process}{equation.2.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2-3}Value Function}{6}{section.2.3}}
\newlabel{sec:value}{{2-3}{6}{Value Function}{section.2.3}{}}
\acronymused{RL}
\citation{sutton1998reinforcement}
\citation{126844}
\citation{babuskaRL}
\newlabel{eq:bellman}{{2-4}{7}{Value Function}{equation.2.3.4}{}}
\newlabel{eq:bellman2}{{2-5}{7}{Value Function}{equation.2.3.5}{}}
\newlabel{eq:optPi}{{2-6}{7}{Value Function}{equation.2.3.6}{}}
\acronymused{RL}
\@writefile{toc}{\contentsline {section}{\numberline {2-4}Policy and value iteration}{7}{section.2.4}}
\newlabel{sec:value_iter}{{2-4}{7}{Policy and value iteration}{section.2.4}{}}
\undonewlabel{acro:PI}
\newlabel{acro:PI}{{2-4}{7}{Policy and value iteration}{section*.21}{}}
\acronymused{PI}
\undonewlabel{acro:VI}
\newlabel{acro:VI}{{2-4}{7}{Policy and value iteration}{section*.22}{}}
\acronymused{VI}
\acronymused{RL}
\acronymused{PI}
\acronymused{VI}
\acronymused{PI}
\@writefile{toc}{\contentsline {section}{\numberline {2-5}Actor Critic Methods}{7}{section.2.5}}
\newlabel{sec:actor}{{2-5}{7}{Actor Critic Methods}{section.2.5}{}}
\acronymused{RL}
\undonewlabel{acro:TD}
\newlabel{acro:TD}{{2-5}{7}{Actor Critic Methods}{section*.25}{}}
\acronymused{TD}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Policy iteration algorithm\relax }}{8}{algocf.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:PI}{{1}{8}{Policy and value iteration}{algocf.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Value iteration algorithm\relax }}{8}{algocf.2}}
\newlabel{alg:VI}{{2}{8}{Policy and value iteration}{algocf.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2-1}{\ignorespaces Actor critic structure\relax }}{9}{figure.caption.26}}
\newlabel{fig:actorCritic}{{2-1}{9}{Actor critic structure\relax }{figure.caption.26}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Actor-critic algorithm\relax }}{9}{algocf.3}}
\newlabel{alg:actorcritic}{{3}{9}{Actor Critic Methods}{algocf.3}{}}
\@setckpt{rl_prelim}{
\setcounter{page}{10}
\setcounter{equation}{6}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{5}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{1}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{lstnumber}{1}
\setcounter{Item}{11}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{20}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{3}
\setcounter{algocfproc}{3}
\setcounter{algocf}{3}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{1}
}
